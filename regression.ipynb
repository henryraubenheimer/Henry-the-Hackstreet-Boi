{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "print(torch.cuda.is_available())\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PotholeAsphaltCNN(nn.Module):\n",
    "    def __init__(self, num_additional_features):\n",
    "        super(PotholeAsphaltCNN, self).__init__()\n",
    "        \n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 400)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(400)\n",
    "        self.dropout_fc1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc_additional = nn.Sequential(\n",
    "            nn.Linear(num_additional_features, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Linear(400 + 100, 128)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(128)\n",
    "        self.dropout_fc2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, 1)  # Output single regression value\n",
    "\n",
    "    def forward(self, x, additional_features):\n",
    "        # First Conv Block\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Second Conv Block\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Third Conv Block\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.dropout_fc1(x)\n",
    "\n",
    "        # Process additional features separately\n",
    "        additional_features = self.fc_additional(additional_features)\n",
    "\n",
    "        # Concatenate CNN features with additional features\n",
    "        x = torch.cat((x, additional_features), dim=1)\n",
    "          \n",
    "        x = F.relu(self.bn_fc2(self.fc2(x)))\n",
    "        x = self.dropout_fc2(x)\n",
    "        \n",
    "        x = self.fc3(x)  # Output layer\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('updated_csv_file.csv')\n",
    "labels_dict = {'p'+str(int(row['Pothole number']))+'.jpg': row['Bags used '] for _, row in label_df.iterrows()}\n",
    "\n",
    "class PotholeDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_dict, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_dict = labels_dict\n",
    "        self.transform = transform\n",
    "        self.image_filenames = os.listdir(image_dir)\n",
    "        self.data = pd.read_csv('updated_csv_file.csv')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Extract label and additional features\n",
    "        label = torch.tensor(self.data.iloc[idx, 1], dtype=torch.float32)\n",
    "        additional_features = torch.tensor(self.data.iloc[idx, 2:].values, dtype=torch.float32)\n",
    "\n",
    "        return image, label, additional_features\n",
    "    \n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to match model input size\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet means and stds\n",
    "])\n",
    "\n",
    "# Paths to image directories\n",
    "train_dir = 'train/cropped_images/'\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PotholeDataset(train_dir, labels_dict, transform=train_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hprau\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\hprau\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 2.0813\n",
      "Epoch 2/15, Loss: 1.8227\n",
      "Epoch 3/15, Loss: 1.7691\n",
      "Epoch 4/15, Loss: 1.7505\n",
      "Epoch 5/15, Loss: 1.7245\n",
      "Epoch 6/15, Loss: 1.6981\n",
      "Epoch 7/15, Loss: 1.6880\n",
      "Epoch 8/15, Loss: 1.6826\n",
      "Epoch 9/15, Loss: 1.6696\n",
      "Epoch 10/15, Loss: 1.6680\n",
      "Epoch 11/15, Loss: 1.6601\n",
      "Epoch 12/15, Loss: 1.6569\n",
      "Epoch 13/15, Loss: 1.6568\n",
      "Epoch 14/15, Loss: 1.6449\n",
      "Epoch 15/15, Loss: 1.6395\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "num_additional_features = 5\n",
    "\n",
    "# Model instantiation\n",
    "model = PotholeAsphaltCNN(num_additional_features)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 15  # Adjust based on your needs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels, additional_features in train_loader:\n",
    "        # Move data to the appropriate device\n",
    "        images, labels, additional_features = images.to(device), labels.to(device), additional_features.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, additional_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    # Calculate and print the average loss for this epoch\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Training complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R² Score: 0.0032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Paths to image directories\n",
    "train_dir = 'train/cropped_images/'\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PotholeDataset(train_dir, labels_dict, transform=train_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "def compute_r2_score(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, additional_features in dataloader:\n",
    "            images, labels, additional_features = images.to(device), labels.to(device), additional_features.to(device)\n",
    "            outputs = model(images, additional_features)\n",
    "            \n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Flatten the lists of predictions and labels\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "    # Compute R² score\n",
    "    r2 = r2_score(all_labels, all_preds)\n",
    "    return r2\n",
    "\n",
    "# Example usage after training\n",
    "train_r2 = compute_r2_score(model, train_loader, device)\n",
    "print(f\"Training R² Score: {train_r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
